# LLM utilizando RAG

## Descrição
Projeto que implementa **LLM com Retrieval-Augmented Generation (RAG)** para melhorar respostas de modelos de linguagem, combinando geração com recuperação de informações externas.

## Estrutura
- **LLM**: modelo base para geração de linguagem.  
- **Retriever**: busca em base de conhecimento/documentos.  
- **RAG**: integra contexto recuperado às respostas.  

## Objetivo
- Aumentar precisão das respostas.  
- Reduzir alucinações do modelo.  
- Utilizar documentos específicos como fonte de verdade.  

## Tecnologias
- Python  
- LangChain / LlamaIndex  
- Vetores (FAISS/ChromaDB)  

## Resultados Esperados
- Respostas contextualizadas.  
- Suporte a domínios específicos.  
- Maior confiabilidade em aplicações práticas.
